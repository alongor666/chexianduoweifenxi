#!/usr/bin/env python3
"""
çŸ¥è¯†åº“ç´¢å¼•ç”Ÿæˆè„šæœ¬
è‡ªåŠ¨æ‰«æçŸ¥è¯†åº“å†…å®¹å¹¶ç”ŸæˆREADMEç´¢å¼•
"""

import os
import sys
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List

class KnowledgeBaseIndexer:
    """çŸ¥è¯†åº“ç´¢å¼•å™¨"""
    
    def __init__(self, kb_path: str):
        self.kb_path = Path(kb_path)
        self.stats = {
            'docs': 0,
            'decisions': 0,
            'code_patterns': 0,
            'configs': 0
        }
        self.index = {
            'documents': [],
            'decisions': [],
            'code_patterns': [],
            'configs': [],
            'tags': {}
        }
    
    def extract_frontmatter(self, file_path: Path) -> Dict:
        """æå–Markdownæ–‡ä»¶çš„YAML frontmatter"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒ¹é…YAML frontmatter
            match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
            if not match:
                return {}
            
            frontmatter = {}
            yaml_content = match.group(1)
            
            for line in yaml_content.split('\n'):
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()
                    
                    # å¤„ç†æ ‡ç­¾æ•°ç»„
                    if key == 'æ ‡ç­¾' and value.startswith('['):
                        tags = re.findall(r'\w+', value)
                        frontmatter[key] = tags
                    else:
                        frontmatter[key] = value
            
            return frontmatter
        
        except Exception as e:
            print(f"  âš ï¸ æå–frontmatterå¤±è´¥ {file_path}: {e}")
            return {}
    
    def scan_documents(self):
        """æ‰«ædocsç›®å½•"""
        docs_dir = self.kb_path / 'docs'
        if not docs_dir.exists():
            return
        
        for md_file in docs_dir.glob('*.md'):
            self.stats['docs'] += 1
            
            metadata = self.extract_frontmatter(md_file)
            doc_entry = {
                'file': str(md_file.relative_to(self.kb_path)),
                'name': md_file.stem,
                'type': metadata.get('æ–‡æ¡£ç±»å‹', 'æœªåˆ†ç±»'),
                'created': metadata.get('åˆ›å»ºæ—¥æœŸ', ''),
                'updated': metadata.get('æ›´æ–°æ—¥æœŸ', ''),
                'tags': metadata.get('æ ‡ç­¾', [])
            }
            
            self.index['documents'].append(doc_entry)
            
            # æ”¶é›†æ ‡ç­¾
            for tag in doc_entry['tags']:
                if tag not in self.index['tags']:
                    self.index['tags'][tag] = []
                self.index['tags'][tag].append(doc_entry['file'])
    
    def scan_decisions(self):
        """æ‰«ædecisionsç›®å½•"""
        decisions_dir = self.kb_path / 'decisions'
        if not decisions_dir.exists():
            return
        
        for md_file in decisions_dir.glob('*.md'):
            self.stats['decisions'] += 1
            
            decision_entry = {
                'file': str(md_file.relative_to(self.kb_path)),
                'name': md_file.stem,
                'created': md_file.stat().st_mtime
            }
            
            self.index['decisions'].append(decision_entry)
    
    def scan_patterns(self):
        """æ‰«æpatternsç›®å½•"""
        patterns_dir = self.kb_path / 'patterns'
        if not patterns_dir.exists():
            return
        
        # æ‰«æä»£ç æ¨¡å¼
        code_dir = patterns_dir / 'code'
        if code_dir.exists():
            for json_file in code_dir.glob('*.json'):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        patterns = json.load(f)
                        self.stats['code_patterns'] += len(patterns)
                        
                        for pattern in patterns:
                            self.index['code_patterns'].append({
                                'name': pattern.get('name', 'æœªå‘½å'),
                                'file': pattern.get('file', ''),
                                'signature': pattern.get('signature', '')
                            })
                except Exception as e:
                    print(f"  âš ï¸ è¯»å–ä»£ç æ¨¡å¼å¤±è´¥ {json_file}: {e}")
        
        # æ‰«æé…ç½®æ¨¡æ¿
        config_dir = patterns_dir / 'configs'
        if config_dir.exists():
            for json_file in config_dir.glob('*.json'):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        configs = json.load(f)
                        self.stats['configs'] += len(configs)
                        
                        for config in configs:
                            self.index['configs'].append({
                                'file': config.get('file', ''),
                                'type': config.get('type', ''),
                            })
                except Exception as e:
                    print(f"  âš ï¸ è¯»å–é…ç½®æ¨¡æ¿å¤±è´¥ {json_file}: {e}")
    
    def generate_readme(self) -> str:
        """ç”ŸæˆREADME.md"""
        readme = f'''# é¡¹ç›®çŸ¥è¯†åº“

> ç´¢å¼•æ›´æ–°äº {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## ğŸ“ ç›®å½•ç»“æ„

```
{self.kb_path.name}/
â”œâ”€â”€ docs/                  # é¡¹ç›®æ–‡æ¡£ ({self.stats['docs']}ä¸ª)
â”œâ”€â”€ decisions/             # æŠ€æœ¯å†³ç­– ({self.stats['decisions']}æ¡)
â”œâ”€â”€ patterns/              # å¯å¤ç”¨æ¨¡å¼
â”‚   â”œâ”€â”€ code/             # ä»£ç æ¨¡å¼ ({self.stats['code_patterns']}ä¸ª)
â”‚   â””â”€â”€ configs/          # é…ç½®æ¨¡æ¿ ({self.stats['configs']}ä¸ª)
â””â”€â”€ reports/              # åˆ†ææŠ¥å‘Š
```

## ğŸ“‹ æ–‡æ¡£ç´¢å¼•

### é¡¹ç›®æ–‡æ¡£

'''
        # æ·»åŠ æ–‡æ¡£åˆ—è¡¨
        for doc in self.index['documents']:
            readme += f"- [{doc['name']}]({doc['file']}) - {doc['type']}\n"
            if doc['tags']:
                tags_str = ', '.join([f'`#{tag}`' for tag in doc['tags']])
                readme += f"  - æ ‡ç­¾: {tags_str}\n"
            if doc['updated']:
                readme += f"  - æœ€åæ›´æ–°: {doc['updated']}\n"
        
        readme += "\n### æŠ€æœ¯å†³ç­–\n\n"
        
        if self.index['decisions']:
            for dec in self.index['decisions']:
                readme += f"- [{dec['name']}]({dec['file']})\n"
        else:
            readme += "*å°šæœªæå–æŠ€æœ¯å†³ç­–ï¼Œè¿è¡Œ `extract_patterns.py` åè‡ªåŠ¨ç”Ÿæˆ*\n"
        
        readme += "\n### ä»£ç æ¨¡å¼\n\n"
        
        if self.index['code_patterns']:
            # åªå±•ç¤ºå‰10ä¸ª
            for pattern in self.index['code_patterns'][:10]:
                readme += f"- `{pattern['name']}` - æ¥è‡ª `{pattern['file']}`\n"
            
            if len(self.index['code_patterns']) > 10:
                readme += f"\n*å…± {len(self.index['code_patterns'])} ä¸ªä»£ç æ¨¡å¼ï¼ŒæŸ¥çœ‹ patterns/code/ è·å–å®Œæ•´åˆ—è¡¨*\n"
        else:
            readme += "*å°šæœªæå–ä»£ç æ¨¡å¼ï¼Œè¿è¡Œ `extract_patterns.py` åè‡ªåŠ¨ç”Ÿæˆ*\n"
        
        readme += "\n## ğŸ·ï¸ æ ‡ç­¾ç´¢å¼•\n\n"
        
        if self.index['tags']:
            for tag, files in sorted(self.index['tags'].items()):
                readme += f"### #{tag}\n"
                for file in files:
                    readme += f"- [{Path(file).stem}]({file})\n"
                readme += "\n"
        else:
            readme += "*æ–‡æ¡£ä¸­å°šæœªä½¿ç”¨æ ‡ç­¾*\n"
        
        readme += f'''
## ğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡

- é¡¹ç›®æ–‡æ¡£: {self.stats['docs']}
- æŠ€æœ¯å†³ç­–: {self.stats['decisions']}
- ä»£ç æ¨¡å¼: {self.stats['code_patterns']}
- é…ç½®æ¨¡æ¿: {self.stats['configs']}
- æ ‡ç­¾æ•°é‡: {len(self.index['tags'])}
- æœ€åæ›´æ–°: {datetime.now().strftime("%Y-%m-%d")}

---

**ä½¿ç”¨è¯´æ˜**: 
- æœ¬ç´¢å¼•ç”± `generate_index.py` è‡ªåŠ¨ç”Ÿæˆ
- ä¿®æ”¹æ–‡æ¡£åè¿è¡Œ `python scripts/generate_index.py <çŸ¥è¯†åº“è·¯å¾„>` æ›´æ–°ç´¢å¼•
- é€šè¿‡ `project-knowledge-base` Skill ç®¡ç†çŸ¥è¯†åº“
'''
        
        return readme
    
    def save_readme(self):
        """ä¿å­˜README.md"""
        readme_path = self.kb_path / 'README.md'
        readme_content = self.generate_readme()
        
        with open(readme_path, 'w', encoding='utf-8') as f:
            f.write(readme_content)
        
        return readme_path

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python generate_index.py <çŸ¥è¯†åº“ç›®å½•>")
        print("ç¤ºä¾‹: python generate_index.py /home/claude/kb")
        sys.exit(1)
    
    kb_path = sys.argv[1]
    
    if not os.path.exists(kb_path):
        print(f"âŒ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨: {kb_path}")
        sys.exit(1)
    
    print(f"ğŸš€ å¼€å§‹ç”ŸæˆçŸ¥è¯†åº“ç´¢å¼•")
    print(f"ğŸ“ çŸ¥è¯†åº“è·¯å¾„: {kb_path}\n")
    
    # åˆ›å»ºç´¢å¼•å™¨
    indexer = KnowledgeBaseIndexer(kb_path)
    
    # æ‰«æå„ç›®å½•
    print("ğŸ” æ‰«ææ–‡æ¡£...")
    indexer.scan_documents()
    
    print("ğŸ” æ‰«ææŠ€æœ¯å†³ç­–...")
    indexer.scan_decisions()
    
    print("ğŸ” æ‰«æå¯å¤ç”¨æ¨¡å¼...")
    indexer.scan_patterns()
    
    # ç”ŸæˆREADME
    print("\nğŸ’¾ ç”ŸæˆREADMEç´¢å¼•...")
    readme_path = indexer.save_readme()
    print(f"  âœ… READMEä¿å­˜è‡³: {readme_path}")
    
    # è¾“å‡ºç»Ÿè®¡
    print(f"\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡:")
    print(f"  - é¡¹ç›®æ–‡æ¡£: {indexer.stats['docs']}")
    print(f"  - æŠ€æœ¯å†³ç­–: {indexer.stats['decisions']}")
    print(f"  - ä»£ç æ¨¡å¼: {indexer.stats['code_patterns']}")
    print(f"  - é…ç½®æ¨¡æ¿: {indexer.stats['configs']}")
    print(f"  - æ ‡ç­¾æ•°é‡: {len(indexer.index['tags'])}")
    
    print(f"\nâœ¨ ç´¢å¼•ç”Ÿæˆå®Œæˆ!")
    
    return 0

if __name__ == '__main__':
    sys.exit(main())
