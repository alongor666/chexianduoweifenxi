#!/usr/bin/env python3
"""
åå®‰ä¿é™©è½¦é™©å‘¨æŠ¥ KPI è®¡ç®—å™¨ v2.0
æ”¯æŒå¤šç§æ•°æ®æ ¼å¼(Excel/CSV)å’Œå­—æ®µæ˜ å°„(ä¸­æ–‡/è‹±æ–‡)
æå–è‘£äº‹ä¼šå…³æ³¨çš„æ ¸å¿ƒæŒ‡æ ‡,æ”¯æŒå¯é…ç½®çš„é¢„è­¦é˜ˆå€¼
"""
import pandas as pd
import numpy as np
import json
import sys
import os
from datetime import datetime

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config():
    """åŠ è½½ä¸šåŠ¡è§„åˆ™é…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), '..', 'config.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {
            "é¢„è­¦é˜ˆå€¼": {
                "ç»¼åˆæˆæœ¬ç‡_ä¸Šé™": 95,
                "æ–°èƒ½æºè½¦èµ”ä»˜ç‡å·®è·": 10,
                "å‡ºé™©é¢‘åº¦_ä¸Šé™": 25
            }
        }

def load_field_mapping():
    """åŠ è½½å­—æ®µæ˜ å°„é…ç½®"""
    mapping_path = os.path.join(os.path.dirname(__file__), '..', 'field_mapping.json')
    try:
        with open(mapping_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print("âš ï¸ Warning: field_mapping.json not found, using fallback mapping", file=sys.stderr)
        return None

CONFIG = load_config()
FIELD_MAPPING = load_field_mapping()

def get_field(df, logical_name):
    """
    æ ¹æ®é€»è¾‘å­—æ®µåè·å–å®é™…æ•°æ®åˆ—
    è‡ªåŠ¨åŒ¹é…ä¸­æ–‡/è‹±æ–‡å­—æ®µå
    """
    if FIELD_MAPPING is None:
        # Fallback: å°è¯•å¸¸è§å­—æ®µå
        fallback_mappings = {
            'premium': ['signed_premium_yuan', 'è·Ÿå•ä¿è´¹(Ten Thousand)', 'ç­¾å•ä¿è´¹'],
            'business_type': ['business_type_category', 'ä¸šåŠ¡ç±»å‹åˆ†ç±»'],
            'third_level_org': ['third_level_organization', 'ä¸‰çº§æœºæ„'],
            'is_nev': ['is_new_energy_vehicle', 'æ˜¯å¦æ–°èƒ½æºè½¦1'],
            'policy_count': ['policy_count', 'ä¿å•æ•°'],
            'claim_cases': ['claim_case_count', 'å‡ºé™©æ¬¡æ•°'],
            'claim_amount': ['reported_claim_payment_yuan', 'æŠ¥æ¡ˆèµ”æ¬¾'],
            'expense_amount': ['expense_amount_yuan', 'è´¹ç”¨é‡‘é¢'],
            'customer_category': ['customer_category_3', 'å®¢æˆ·ç±»åˆ«3'],
            'renewal_status': ['renewal_status', 'ç»­ä¿æƒ…å†µ']
        }
        aliases = fallback_mappings.get(logical_name, [])
    else:
        field_config = FIELD_MAPPING['field_mappings'].get(logical_name, {})
        aliases = field_config.get('aliases', [])

    # å°è¯•åŒ¹é…å­—æ®µ
    for alias in aliases:
        if alias in df.columns:
            return df[alias]

    # æœªæ‰¾åˆ°å­—æ®µ
    raise KeyError(f"æ‰¾ä¸åˆ°é€»è¾‘å­—æ®µ '{logical_name}' å¯¹åº”çš„å®é™…å­—æ®µã€‚å°è¯•è¿‡: {aliases}")

def get_field_name(df, logical_name):
    """è·å–å®é™…å­˜åœ¨çš„å­—æ®µå"""
    if FIELD_MAPPING is None:
        fallback_mappings = {
            'premium': ['signed_premium_yuan', 'è·Ÿå•ä¿è´¹(Ten Thousand)'],
            'business_type': ['business_type_category', 'ä¸šåŠ¡ç±»å‹åˆ†ç±»']
        }
        aliases = fallback_mappings.get(logical_name, [])
    else:
        field_config = FIELD_MAPPING['field_mappings'].get(logical_name, {})
        aliases = field_config.get('aliases', [])

    for alias in aliases:
        if alias in df.columns:
            return alias

    return None

def normalize_boolean_field(series):
    """æ ‡å‡†åŒ–å¸ƒå°”å­—æ®µ(True/False, æ˜¯/å¦ç­‰)"""
    true_values = [True, 'True', 'æ˜¯', 'Y', 'yes', 1, '1']
    return series.isin(true_values)

def load_and_clean_data(file_path):
    """åŠ è½½å¹¶æ¸…æ´—æ•°æ®,è‡ªåŠ¨æ£€æµ‹æ ¼å¼"""
    file_ext = os.path.splitext(file_path)[1].lower()

    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ–¹å¼
    if file_ext in ['.xlsx', '.xls']:
        df = pd.read_excel(file_path)
        print(f"âœ… å·²åŠ è½½ Excel æ–‡ä»¶: {file_path}", file=sys.stderr)
    elif file_ext == '.csv':
        # å°è¯•ä¸åŒç¼–ç 
        for encoding in ['utf-8', 'utf-8-sig', 'gb2312', 'gbk']:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                print(f"âœ… å·²åŠ è½½ CSV æ–‡ä»¶: {file_path} (ç¼–ç : {encoding})", file=sys.stderr)
                break
            except UnicodeDecodeError:
                continue
        else:
            raise ValueError(f"æ— æ³•ä»¥ä»»ä½•ç¼–ç è¯»å–CSVæ–‡ä»¶: {file_path}")
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")

    print(f"ğŸ“Š æ•°æ®è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)}", file=sys.stderr)
    print(f"ğŸ“‹ åˆ—å: {list(df.columns[:10])}..." if len(df.columns) > 10 else f"ğŸ“‹ åˆ—å: {list(df.columns)}", file=sys.stderr)

    return df

def calculate_business_scale(df):
    """ä¸šåŠ¡è§„æ¨¡æŒ‡æ ‡"""
    premium = get_field(df, 'premium')
    policy_count = get_field(df, 'policy_count')
    business_type = get_field(df, 'business_type')

    # æ£€æŸ¥ä¿è´¹å­—æ®µå•ä½(æ˜¯å¦éœ€è¦è½¬æ¢)
    premium_field_name = get_field_name(df, 'premium')
    if 'Ten Thousand' in premium_field_name:
        premium_sum = premium.sum()  # å·²ç»æ˜¯ä¸‡å…ƒ
        unit = "ä¸‡å…ƒ"
    else:
        premium_sum = premium.sum() / 10000  # è½¬æ¢ä¸ºä¸‡å…ƒ
        unit = "ä¸‡å…ƒ(ä»å…ƒè½¬æ¢)"

    total_policies = policy_count.sum()
    avg_premium = premium.sum() / total_policies if total_policies > 0 else 0

    # ä¸šåŠ¡ç±»å‹åˆ†å¸ƒ
    business_type_dist = df.groupby(business_type.name)[premium.name].sum().sort_values(ascending=False).head(5).to_dict()

    return {
        'æ€»ä¿è´¹_ä¸‡å…ƒ': round(premium_sum, 2),
        'ä¿è´¹å•ä½': unit,
        'ä¿å•æ•°é‡': int(total_policies),
        'å•å‡ä¿è´¹_å…ƒ': round(avg_premium if 'yuan' in premium_field_name else avg_premium * 10000, 2),
        'ä¸šåŠ¡ç±»å‹å æ¯”': business_type_dist
    }

def calculate_profitability(df):
    """ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡"""
    premium = get_field(df, 'premium')
    claim_amount = get_field(df, 'claim_amount')
    expense_amount = get_field(df, 'expense_amount')

    total_premium = premium.sum()
    total_claims = claim_amount.sum()
    total_expense = expense_amount.sum()

    loss_ratio = (total_claims / total_premium * 100) if total_premium > 0 else 0
    expense_ratio = (total_expense / total_premium * 100) if total_premium > 0 else 0
    combined_ratio = loss_ratio + expense_ratio

    # å°è¯•è·å–è¾¹é™…è´¡çŒ®
    try:
        marginal_contrib = get_field(df, 'marginal_contribution')
        total_margin = marginal_contrib.sum()
    except KeyError:
        total_margin = total_premium - total_claims - total_expense

    return {
        'èµ”ä»˜ç‡_%': round(loss_ratio, 2),
        'è´¹ç”¨ç‡_%': round(expense_ratio, 2),
        'ç»¼åˆæˆæœ¬ç‡_%': round(combined_ratio, 2),
        'è¾¹é™…è´¡çŒ®_å…ƒ': round(total_margin, 2),
        'æ€»èµ”æ¬¾_å…ƒ': round(total_claims, 2),
        'æ€»è´¹ç”¨_å…ƒ': round(total_expense, 2)
    }

def calculate_nev_insights(df):
    """æ–°èƒ½æºè½¦ä¸“é¢˜åˆ†æ"""
    try:
        is_nev = normalize_boolean_field(get_field(df, 'is_nev'))
        premium = get_field(df, 'premium')
        claim_amount = get_field(df, 'claim_amount')
        policy_count = get_field(df, 'policy_count')

        nev_mask = is_nev
        traditional_mask = ~is_nev

        nev_policies = policy_count[nev_mask].sum()
        total_policies = policy_count.sum()

        if nev_policies == 0:
            return {'æ–°èƒ½æºè½¦æ•°æ®': 'æ— æ–°èƒ½æºè½¦ä¿å•'}

        nev_premium = premium[nev_mask].sum()
        nev_claims = claim_amount[nev_mask].sum()
        traditional_claims = claim_amount[traditional_mask].sum()
        traditional_premium = premium[traditional_mask].sum()

        nev_loss_ratio = (nev_claims / nev_premium * 100) if nev_premium > 0 else 0
        traditional_loss_ratio = (traditional_claims / traditional_premium * 100) if traditional_premium > 0 else 0

        return {
            'æ–°èƒ½æºè½¦æ¸—é€ç‡_%': round(nev_policies / total_policies * 100, 2),
            'æ–°èƒ½æºè½¦ä¿å•æ•°': int(nev_policies),
            'æ–°èƒ½æºè½¦èµ”ä»˜ç‡_%': round(nev_loss_ratio, 2),
            'ä¼ ç»Ÿè½¦èµ”ä»˜ç‡_%': round(traditional_loss_ratio, 2),
            'èµ”ä»˜ç‡å·®è·_pp': round(nev_loss_ratio - traditional_loss_ratio, 2)
        }
    except KeyError as e:
        return {'æ–°èƒ½æºè½¦æ•°æ®': f'å­—æ®µç¼ºå¤±: {str(e)}'}

def calculate_risk_metrics(df):
    """é£é™©ç®¡ç†æŒ‡æ ‡"""
    try:
        claim_cases = get_field(df, 'claim_cases')
        policy_count = get_field(df, 'policy_count')
        claim_amount = get_field(df, 'claim_amount')

        total_policies = policy_count.sum()
        total_claims = claim_cases.sum()
        total_claim_amount = claim_amount.sum()

        claim_frequency = (total_claims / total_policies * 100) if total_policies > 0 else 0
        avg_claim_amount = (total_claim_amount / total_claims) if total_claims > 0 else 0

        return {
            'å‡ºé™©é¢‘åº¦_%': round(claim_frequency, 2),
            'æ€»æ¡ˆä»¶æ•°': int(total_claims),
            'æ¡ˆå‡èµ”æ¬¾_å…ƒ': round(avg_claim_amount, 2),
            'å‡ºé™©ä¿å•å æ¯”_%': round(claim_frequency, 2)
        }
    except KeyError as e:
        return {'é£é™©æŒ‡æ ‡': f'å­—æ®µç¼ºå¤±: {str(e)}'}

def calculate_customer_mix(df):
    """å®¢æˆ·ç»“æ„åˆ†æ"""
    try:
        renewal_status = get_field(df, 'renewal_status')
        premium = get_field(df, 'premium')
        policy_count = get_field(df, 'policy_count')
        customer_category = get_field(df, 'customer_category')
        third_level_org = get_field(df, 'third_level_org')

        # ç»­ä¿ç‡è®¡ç®—
        renewal_mask = renewal_status == 'ç»­ä¿'
        renewal_policies = policy_count[renewal_mask].sum()
        total_policies = policy_count.sum()
        renewal_rate = (renewal_policies / total_policies * 100) if total_policies > 0 else 0

        # å®¢æˆ·ç±»åˆ«åˆ†å¸ƒ
        customer_dist = df.groupby(customer_category.name)[premium.name].sum().sort_values(ascending=False).head(5).to_dict()

        # ä¸‰çº§æœºæ„è´¡çŒ®
        org_contrib = df.groupby(third_level_org.name)[premium.name].sum().sort_values(ascending=False).head(5).to_dict()

        return {
            'ç»­ä¿ç‡_%': round(renewal_rate, 2),
            'ç»­ä¿ä¿å•æ•°': int(renewal_policies),
            'å®¢æˆ·ç±»åˆ«åˆ†å¸ƒ_TOP5': customer_dist,
            'ä¸‰çº§æœºæ„è´¡çŒ®_TOP5': org_contrib
        }
    except KeyError as e:
        return {'å®¢æˆ·ç»“æ„': f'å­—æ®µç¼ºå¤±: {str(e)}'}

def generate_action_items(kpis):
    """åŸºäº KPI è‡ªåŠ¨ç”Ÿæˆè¡ŒåŠ¨å»ºè®®"""
    actions = []
    thresholds = CONFIG.get('é¢„è­¦é˜ˆå€¼', {})

    # ç»¼åˆæˆæœ¬ç‡é¢„è­¦
    if 'ç›ˆåˆ©èƒ½åŠ›' in kpis and 'ç»¼åˆæˆæœ¬ç‡_%' in kpis['ç›ˆåˆ©èƒ½åŠ›']:
        combined_ratio = kpis['ç›ˆåˆ©èƒ½åŠ›']['ç»¼åˆæˆæœ¬ç‡_%']
        ratio_limit = thresholds.get('ç»¼åˆæˆæœ¬ç‡_ä¸Šé™', 95)
        ratio_danger = thresholds.get('ç»¼åˆæˆæœ¬ç‡_å±é™©çº¿', 100)

        if combined_ratio > ratio_danger:
            actions.append(f"âš ï¸ ç»¼åˆæˆæœ¬ç‡è¾¾{combined_ratio}%ï¼Œè¶…è¿‡å±é™©çº¿ï¼Œå»ºè®®ç«‹å³æ”¶ç´§æ‰¿ä¿")
        elif combined_ratio > ratio_limit:
            actions.append(f"âš ï¸ ç»¼åˆæˆæœ¬ç‡è¾¾{combined_ratio}%ï¼Œå»ºè®®æ”¶ç´§é«˜æˆæœ¬ä¸šåŠ¡æ‰¿ä¿")

    # æ–°èƒ½æºè½¦é¢„è­¦
    if 'æ–°èƒ½æºè½¦åˆ†æ' in kpis and 'èµ”ä»˜ç‡å·®è·_pp' in kpis['æ–°èƒ½æºè½¦åˆ†æ']:
        gap = kpis['æ–°èƒ½æºè½¦åˆ†æ']['èµ”ä»˜ç‡å·®è·_pp']
        nev_gap_threshold = thresholds.get('æ–°èƒ½æºè½¦èµ”ä»˜ç‡å·®è·', 10)

        if gap > nev_gap_threshold:
            actions.append(f"ğŸ”‹ æ–°èƒ½æºè½¦èµ”ä»˜ç‡è¾ƒä¼ ç»Ÿè½¦é«˜{round(gap, 1)}ä¸ªç™¾åˆ†ç‚¹ï¼Œå»ºè®®ä¼˜åŒ–å®šä»·æ¨¡å‹")

    # å‡ºé™©é¢‘åº¦é¢„è­¦
    if 'é£é™©æŒ‡æ ‡' in kpis and 'å‡ºé™©é¢‘åº¦_%' in kpis['é£é™©æŒ‡æ ‡']:
        freq = kpis['é£é™©æŒ‡æ ‡']['å‡ºé™©é¢‘åº¦_%']
        freq_limit = thresholds.get('å‡ºé™©é¢‘åº¦_ä¸Šé™', 25)

        if freq > freq_limit:
            actions.append(f"ğŸš¨ å¹³å‡å‡ºé™©é¢‘åº¦{freq}%åé«˜ï¼Œå»ºè®®åŠ å¼ºé£é™©ç­›æŸ¥")

    # ç»­ä¿ç‡é¢„è­¦
    if 'å®¢æˆ·ç»“æ„' in kpis and 'ç»­ä¿ç‡_%' in kpis['å®¢æˆ·ç»“æ„']:
        renewal_rate = kpis['å®¢æˆ·ç»“æ„']['ç»­ä¿ç‡_%']

        if renewal_rate < 45:
            actions.append(f"ğŸ“‰ ç»­ä¿ç‡{renewal_rate}%åä½ï¼Œå»ºè®®å¼ºåŒ–å®¢æˆ·ç»´æŠ¤")

    return actions if actions else ["âœ… æœ¬å‘¨ä¸šåŠ¡æŒ‡æ ‡è¿è¡Œå¹³ç¨³"]

def main():
    if len(sys.argv) < 2:
        print(json.dumps({"error": "Usage: python kpi_calculator.py <file_path> [week_number]"}, ensure_ascii=False))
        sys.exit(1)

    file_path = sys.argv[1]
    week_num = sys.argv[2] if len(sys.argv) > 2 else "æœªçŸ¥"

    try:
        print(f"\nğŸš€ å¼€å§‹å¤„ç†: {file_path}", file=sys.stderr)
        df = load_and_clean_data(file_path)

        kpis = {
            'week_number': week_num,
            'calculation_date': datetime.now().strftime("%Y-%m-%d"),
            'data_summary': {
                'total_records': len(df),
                'data_source': os.path.basename(file_path)
            },
            'ä¸šåŠ¡è§„æ¨¡': calculate_business_scale(df),
            'ç›ˆåˆ©èƒ½åŠ›': calculate_profitability(df),
            'æ–°èƒ½æºè½¦åˆ†æ': calculate_nev_insights(df),
            'é£é™©æŒ‡æ ‡': calculate_risk_metrics(df),
            'å®¢æˆ·ç»“æ„': calculate_customer_mix(df)
        }

        kpis['è¡ŒåŠ¨å»ºè®®'] = generate_action_items(kpis)

        # ä¿å­˜ KPI åˆ° JSON
        output_dir = os.path.join(os.path.dirname(__file__), '..')
        output_path = os.path.join(output_dir, f'kpis_week_{week_num}.json')

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(kpis, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… KPIè®¡ç®—å®Œæˆ", file=sys.stderr)
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}", file=sys.stderr)
        print(f"ğŸ“Š ç»¼åˆæˆæœ¬ç‡: {kpis['ç›ˆåˆ©èƒ½åŠ›'].get('ç»¼åˆæˆæœ¬ç‡_%', 'N/A')}%", file=sys.stderr)

        # æ ‡å‡†è¾“å‡ºJSONç»“æœ
        print(json.dumps({
            "status": "success",
            "kpi_file": output_path,
            "summary": {
                "week": week_num,
                "records": len(df),
                "combined_ratio": kpis['ç›ˆåˆ©èƒ½åŠ›'].get('ç»¼åˆæˆæœ¬ç‡_%', None)
            }
        }, ensure_ascii=False, indent=2))

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"\nâŒ é”™è¯¯: {str(e)}", file=sys.stderr)
        print(error_detail, file=sys.stderr)
        print(json.dumps({"error": str(e), "traceback": error_detail}, ensure_ascii=False))
        sys.exit(1)

if __name__ == '__main__':
    main()
