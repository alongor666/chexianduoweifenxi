#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSV è½¬ DuckDB æ•°æ®åº“è„šæœ¬

åŠŸèƒ½:
1. è¯»å–å¤šä¸ª CSV æ–‡ä»¶å¹¶åˆå¹¶åˆ°å•ä¸ª DuckDB æ•°æ®åº“
2. è‡ªåŠ¨æ•°æ®æ¸…æ´—å’ŒéªŒè¯
3. åˆ›å»ºç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½
4. å‹ç¼©å­˜å‚¨å‡å°æ–‡ä»¶ä½“ç§¯

ä½¿ç”¨æ–¹æ³•:
    python scripts/csv_to_duckdb.py

è¾“å‡º:
    insurance_data.duckdb - ä¼˜åŒ–åçš„æ•°æ®åº“æ–‡ä»¶
"""

import duckdb
import glob
import os
import sys
from pathlib import Path
from datetime import datetime

class CSVToDuckDBConverter:
    """CSV åˆ° DuckDB è½¬æ¢å™¨"""

    def __init__(self, csv_pattern: str = "å®é™…æ•°æ®/*.csv", output_db: str = "insurance_data.duckdb"):
        self.csv_pattern = csv_pattern
        self.output_db = output_db
        self.conn = None

    def find_csv_files(self) -> list:
        """æŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆæ¨¡å¼çš„ CSV æ–‡ä»¶"""
        csv_files = sorted(glob.glob(self.csv_pattern))

        if not csv_files:
            print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°åŒ¹é…çš„ CSV æ–‡ä»¶ ({self.csv_pattern})")
            sys.exit(1)

        print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶:")
        for i, file in enumerate(csv_files, 1):
            size_mb = os.path.getsize(file) / (1024 * 1024)
            print(f"   {i}. {Path(file).name} ({size_mb:.2f} MB)")

        return csv_files

    def create_database(self):
        """åˆ›å»ºæˆ–æ‰“å¼€æ•°æ®åº“è¿æ¥"""
        print(f"\nğŸ”¨ åˆ›å»ºæ•°æ®åº“: {self.output_db}")

        # å¦‚æœæ•°æ®åº“å·²å­˜åœ¨,åˆ é™¤æ—§æ–‡ä»¶
        if os.path.exists(self.output_db):
            print(f"âš ï¸  æ£€æµ‹åˆ°å·²å­˜åœ¨çš„æ•°æ®åº“æ–‡ä»¶,å°†è¢«è¦†ç›–")
            os.remove(self.output_db)

        self.conn = duckdb.connect(self.output_db)
        print("âœ… æ•°æ®åº“è¿æ¥å·²å»ºç«‹")

    def import_csv_files(self, csv_files: list):
        """å¯¼å…¥æ‰€æœ‰ CSV æ–‡ä»¶åˆ°æ•°æ®åº“"""
        print(f"\nğŸ“¥ å¼€å§‹å¯¼å…¥ CSV æ–‡ä»¶...")

        total_start = datetime.now()

        for i, csv_file in enumerate(csv_files, 1):
            file_start = datetime.now()
            print(f"\n   [{i}/{len(csv_files)}] å¤„ç†: {Path(csv_file).name}")

            try:
                if i == 1:
                    # ç¬¬ä¸€ä¸ªæ–‡ä»¶: åˆ›å»ºè¡¨
                    self.conn.execute(f"""
                        CREATE TABLE insurance_records AS
                        SELECT * FROM read_csv_auto('{csv_file}',
                            header=true,
                            sample_size=-1,
                            ignore_errors=false
                        )
                    """)
                    print(f"      âœ… è¡¨å·²åˆ›å»º")
                else:
                    # åç»­æ–‡ä»¶: è¿½åŠ æ•°æ®
                    self.conn.execute(f"""
                        INSERT INTO insurance_records
                        SELECT * FROM read_csv_auto('{csv_file}',
                            header=true,
                            sample_size=-1,
                            ignore_errors=false
                        )
                    """)
                    print(f"      âœ… æ•°æ®å·²è¿½åŠ ")

                # æ˜¾ç¤ºå¯¼å…¥è€—æ—¶
                elapsed = (datetime.now() - file_start).total_seconds()
                print(f"      â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")

            except Exception as e:
                print(f"      âŒ å¯¼å…¥å¤±è´¥: {e}")
                raise

        total_elapsed = (datetime.now() - total_start).total_seconds()
        print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶å¯¼å…¥å®Œæˆï¼Œæ€»è€—æ—¶: {total_elapsed:.2f}ç§’")

    def clean_data(self):
        """æ•°æ®æ¸…æ´—ï¼šåˆ é™¤æ— æ•ˆè®°å½•"""
        print(f"\nğŸ§¹ æ•°æ®æ¸…æ´—...")

        # åˆ é™¤å…³é”®å­—æ®µä¸ºç©ºçš„è®°å½•
        result = self.conn.execute("""
            DELETE FROM insurance_records
            WHERE snapshot_date IS NULL
               OR policy_start_year IS NULL
               OR week_number IS NULL
               OR signed_premium_yuan IS NULL
        """)

        deleted_count = result.fetchall()[0][0] if result else 0

        if deleted_count > 0:
            print(f"   âš ï¸  åˆ é™¤äº† {deleted_count} æ¡æ— æ•ˆè®°å½•")
        else:
            print(f"   âœ… æ•°æ®å®Œæ•´ï¼Œæ— éœ€æ¸…ç†")

    def create_indexes(self):
        """åˆ›å»ºç´¢å¼•ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"""
        print(f"\nâš¡ åˆ›å»ºç´¢å¼•...")

        indexes = [
            ("idx_week", "week_number"),
            ("idx_year", "policy_start_year"),
            ("idx_org", "third_level_organization"),
            ("idx_business", "business_type_category"),
            ("idx_customer", "customer_category_3"),
            ("idx_insurance_type", "insurance_type"),
            ("idx_year_week", "policy_start_year, week_number"),  # å¤åˆç´¢å¼•
        ]

        for idx_name, columns in indexes:
            try:
                self.conn.execute(f"CREATE INDEX {idx_name} ON insurance_records({columns})")
                print(f"   âœ… {idx_name}: {columns}")
            except Exception as e:
                print(f"   âš ï¸  {idx_name} åˆ›å»ºå¤±è´¥: {e}")

    def analyze_data(self):
        """åˆ†ææ•°æ®å¹¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š æ•°æ®ç»Ÿè®¡:")

        # åŸºæœ¬ç»Ÿè®¡
        stats = self.conn.execute("""
            SELECT
                COUNT(*) as total_records,
                COUNT(DISTINCT week_number) as week_count,
                MIN(week_number) as min_week,
                MAX(week_number) as max_week,
                COUNT(DISTINCT third_level_organization) as org_count,
                COUNT(DISTINCT business_type_category) as business_type_count,
                SUM(signed_premium_yuan) as total_premium_yuan,
                SUM(policy_count) as total_policy_count
            FROM insurance_records
        """).fetchone()

        print(f"""
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   æ€»è®°å½•æ•°:     {stats[0]:,} æ¡
   å‘¨æ¬¡èŒƒå›´:     ç¬¬ {stats[2]} å‘¨ ~ ç¬¬ {stats[3]} å‘¨ (å…± {stats[1]} å‘¨)
   ä¸‰çº§æœºæ„:     {stats[4]} ä¸ª
   ä¸šåŠ¡ç±»å‹:     {stats[5]} ç§
   ç­¾å•ä¿è´¹:     {stats[6]/10000:,.2f} ä¸‡å…ƒ
   ä¿å•ä»¶æ•°:     {stats[7]:,} ä»¶
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        """)

        # å‘¨åº¦åˆ†å¸ƒ
        print(f"   ğŸ“… å„å‘¨æ•°æ®é‡:")
        weekly_stats = self.conn.execute("""
            SELECT
                week_number,
                COUNT(*) as record_count,
                SUM(signed_premium_yuan)/10000 as premium_wan
            FROM insurance_records
            GROUP BY week_number
            ORDER BY week_number
        """).fetchall()

        for week, count, premium in weekly_stats:
            print(f"      ç¬¬ {week} å‘¨: {count:,} æ¡è®°å½•, {premium:,.2f} ä¸‡å…ƒ")

    def optimize_database(self):
        """ä¼˜åŒ–æ•°æ®åº“: å‹ç¼©å’Œæ•´ç†"""
        print(f"\nğŸ—œï¸  ä¼˜åŒ–æ•°æ®åº“...")

        # VACUUM å‘½ä»¤ä¼š:
        # 1. å›æ”¶æœªä½¿ç”¨çš„ç©ºé—´
        # 2. å‹ç¼©æ•°æ®æ–‡ä»¶
        # 3. é‡ç»„æ•°æ®ä»¥æé«˜æŸ¥è¯¢æ•ˆç‡
        self.conn.execute("VACUUM")
        self.conn.execute("ANALYZE")

        print(f"   âœ… æ•°æ®åº“å·²ä¼˜åŒ–")

    def get_database_info(self):
        """è·å–æ•°æ®åº“æ–‡ä»¶ä¿¡æ¯"""
        if os.path.exists(self.output_db):
            size_mb = os.path.getsize(self.output_db) / (1024 * 1024)
            print(f"\nğŸ’¾ æ•°æ®åº“æ–‡ä»¶:")
            print(f"   è·¯å¾„: {os.path.abspath(self.output_db)}")
            print(f"   å¤§å°: {size_mb:.2f} MB")

            # ä¼°ç®—å‹ç¼©æ¯”
            csv_total_size = sum(os.path.getsize(f) for f in glob.glob(self.csv_pattern))
            csv_total_mb = csv_total_size / (1024 * 1024)
            compression_ratio = (1 - size_mb / csv_total_mb) * 100 if csv_total_mb > 0 else 0

            print(f"   å‹ç¼©æ¯”: {compression_ratio:.1f}% (åŸå§‹CSV: {csv_total_mb:.2f} MB)")

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            print(f"\nâœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")

    def convert(self):
        """æ‰§è¡Œå®Œæ•´çš„è½¬æ¢æµç¨‹"""
        try:
            print("=" * 80)
            print("ğŸš€ CSV è½¬ DuckDB è½¬æ¢å·¥å…·")
            print("=" * 80)

            # 1. æŸ¥æ‰¾ CSV æ–‡ä»¶
            csv_files = self.find_csv_files()

            # 2. åˆ›å»ºæ•°æ®åº“
            self.create_database()

            # 3. å¯¼å…¥æ•°æ®
            self.import_csv_files(csv_files)

            # 4. æ¸…æ´—æ•°æ®
            self.clean_data()

            # 5. åˆ›å»ºç´¢å¼•
            self.create_indexes()

            # 6. ä¼˜åŒ–æ•°æ®åº“
            self.optimize_database()

            # 7. åˆ†ææ•°æ®
            self.analyze_data()

            # 8. æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            self.get_database_info()

            print("\n" + "=" * 80)
            print("ğŸ‰ è½¬æ¢æˆåŠŸå®Œæˆï¼")
            print("=" * 80)
            print(f"\nä¸‹ä¸€æ­¥: åœ¨ç½‘é¡µä¸­é€‰æ‹© {self.output_db} æ–‡ä»¶è¿›è¡Œåˆ†æ")

        except Exception as e:
            print(f"\nâŒ è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            sys.exit(1)
        finally:
            self.close()


def main():
    """ä¸»å‡½æ•°"""
    converter = CSVToDuckDBConverter()
    converter.convert()


if __name__ == "__main__":
    main()
